# MVP 
## Intro & Goal
The problem: Approximately 250,000-500,000 Americans (and some Canadians) use American Sign Langugage, yet we at *appname* believe that number should be higher. Our goal is to make American Sign Language gestures accessible to those who have not yet been exposed to this language and use these translations to increase knowledge and understanding of ASL. 

*app name* is a translation app that uses tensorflow.js machine learning models ( to translate American sign language. 

## Who is it for?
The app is for people who want to translate basic ASL phrases or are interested in learning more about ASL.

## Proof of concept iteration Goals

## Tech Stack
* React
* Node.js
* Tensorflow.js
* Sequelize
* Express
* Redux
* React webcam

## Tier 1
## As a user, I want to be able to:
* As a visitory:
  * Sign up as a user
    * Name (first and last), email, phone number, camera accessibility
  * Login if your account has already been created
  * Will see demo video on homepage so they know what they're signing up for
  * See a header with Routes to Login, Signup, Home, About
  * See a nice logo :)
* As a logged in visitor: 
  * Users will see a detection box in their camera screen that will indicate if the model can detect the hand
  * See a header with Routes to Logout, Home, About, Translate, Lessons
  * See a nice logo :)
  * Can accept or deny access to webcam, if user has already accepted webcam access they don't have to reaccept
  * Can sign 3 phrases(we'll decide those later) and those phrases will be translated on the same page
  * 

## As an engineer, I want to:
* 

## Tier 2
## As a user, I want to be able to:
* We want to attempt to get this working in a React Native mobile app
* 


